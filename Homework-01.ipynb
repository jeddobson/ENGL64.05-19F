{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Cultural Analytics: Homework #1</h1></center>\n",
    "\n",
    "<center><b>Due</b> 11:59PM 9/27/2019</center>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Title Search Analytics\n",
    "# HW1.1\n",
    "#####################################################\n",
    "\n",
    "# This lines tell the Python interpreter to load some additional functions.\n",
    "# We need functions to parse Comma Separated Value (CSV) data.\n",
    "import csv\n",
    "\n",
    "# we'll set a variable to hold the number of records read from this CSV file.\n",
    "ln = 0\n",
    "\n",
    "# as above, we'll create a metadata variable (overwritting the previous variable)\n",
    "metadata=list()\n",
    "\n",
    "# Now we open the CSV file and read each line, appending to the metadata list:\n",
    "with open('data/Underwood_ch1/allgenremeta.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter = ',')\n",
    "    for row in reader:\n",
    "        metadata.append(row)\n",
    "        \n",
    "        # increment our counter\n",
    "        ln += 1\n",
    "\n",
    "# tell us how many entries we've read\n",
    "print(\"read %s lines\" % ln)\n",
    "\n",
    "# Let's remove the header (our \"metadata\") for easier processing:\n",
    "metadata = metadata[1:]\n",
    "\n",
    "# This metadata file contains 5,751 entries about a sample of books from \n",
    "# the 18th to 20th century. Some of the entries have uncertain publication \n",
    "# dates and there are three different genres:\n",
    "#\n",
    "# poe = poetry\n",
    "# fic = fiction\n",
    "# bio = biography\n",
    "\n",
    "cleaned_metadata=list()\n",
    "for book in metadata:\n",
    "\n",
    "    # if the date just contains digits (i.e., just a year-of-publication)\n",
    "    if book[2].isdigit() == True:\n",
    "        \n",
    "        ##########################\n",
    "        # only select for fiction\n",
    "        ##########################\n",
    "        if book[5] == \"fic\":\n",
    "            cleaned_metadata.append(book)\n",
    "            \n",
    "# Search for Patterns\n",
    "i = 0\n",
    "for book in cleaned_metadata:\n",
    "    title = book[10]\n",
    "    \n",
    "    # THIS LINE WILL NEED MODIFICATION\n",
    "    # Replace \"XXXX\" with search term.\n",
    "    \n",
    "    if title.lower().startswith(\"XXXX\"):\n",
    "        i += 1\n",
    "print(\"Found\",i,\"titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #1:</b> In no more than two-hundred and fifty words respond the following prompt: Replace the XXXX with a key term and run the above cell. Try another type of query with the title string. Try a different genre. What did you notice? What questions do you have?\n",
    "\n",
    "Response goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Entropic Poem\n",
    "# HW1.2\n",
    "#####################################################\n",
    "\n",
    "# cut-and-paste some text into the space between the \"\"\" markers\n",
    "source_text = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# preprocess using the Natural Language Toolkit (NLTK) Tokenizer\n",
    "import nltk\n",
    "tokens = nltk.word_tokenize(source_text)\n",
    "\n",
    "# drop to lowercase\n",
    "tokens = [word.lower() for word in tokens]\n",
    "\n",
    "# create our vocabulary \n",
    "vocab = dict()\n",
    "\n",
    "# now produce the entropic poem\n",
    "for word in tokens:\n",
    "    if word not in vocab:\n",
    "        vocab[word] = tokens.count(word)\n",
    "        print(vocab[word],word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #2:</b> In no more than two-hundred and fifty words respond the following prompt: Cut-and-paste some text into the space between the \"\"\" markers above and run the cell. Why did you select the text that you selected? What did you notice about your \"entropic poem?\" Does it work better with certain kinds of texts? \n",
    "\n",
    "Response goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Type/Token Ratios\n",
    "# HW1.3\n",
    "#####################################################\n",
    "\n",
    "from tsvdro import tsvdro\n",
    "from glob import glob\n",
    "\n",
    "dataset=list()\n",
    "for document in glob('data/Underwood_ch1/ny*.dro'):\n",
    "    dataset.append(tsvdro.load(document))\n",
    "\n",
    "\n",
    "# How many texts per category?\n",
    "n_documents = 25\n",
    "selected_documents=list()\n",
    "\n",
    "counters=dict()\n",
    "counters['bio'] = 0\n",
    "counters['fic'] = 0\n",
    "counters['poe'] = 0\n",
    "\n",
    "for i in dataset:\n",
    "    if i['header']['bibliographic_data']['genre'] == \"bio\" and counters['bio'] < n_documents:\n",
    "            selected_documents.append(i)\n",
    "            counters['bio'] += 1\n",
    "    if i['header']['bibliographic_data']['genre'] == \"fic\" and counters['fic'] < n_documents:\n",
    "            selected_documents.append(i)\n",
    "            counters['fic'] += 1\n",
    "    if i['header']['bibliographic_data']['genre'] == \"poe\" and counters['poe'] < n_documents:\n",
    "            selected_documents.append(i)\n",
    "            counters['poe'] += 1\n",
    "\n",
    "# free up some memory\n",
    "import gc\n",
    "del dataset\n",
    "gc.collect()\n",
    "\n",
    "# now process individual documents\n",
    "for document in selected_documents:\n",
    "    tokens = sum([int(x) for x in document['data'].values()])\n",
    "    types = len(document['data'])\n",
    "    print(document['header']['bibliographic_data']['genre'],types/tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #3:</b> In no more than two-hundred and fifty words respond the following prompt: What surprises you about these results? What questions do you have about the dataset? What information do you need to answer these questions?\n",
    "\n",
    "Response goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
